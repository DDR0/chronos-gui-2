<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<title>Chronos Coordinator D-Bus API Documentation</title>
		
		<style>
			/* Originally from http://bettermotherfuckingwebsite.com */
			body {
				display: flex;
				flex-direction: column;
				align-items: center;
				margin: 40px 2%;
				line-height: 1.6;
				font-size: 18px;
				color: #444;
				padding: 0 10px;
				tab-size: 4;
				overflow-wrap: break-word; /*Can't be "anywhere", because of FF bug with table sizing.*/
			}
			
			body > * {
				max-width: 650px;
			}
			
			body > table {
				max-width: 975px;
			}
			
			body > code, .codeblock {
				white-space: pre;
				overflow-x: auto;
				display: block;
				-moz-tab-size: 4;
				-o-tab-size:   4;
				tab-size:      4;
			}
			
			code, .codeblock {
				background: rgba(0,0,0, 0.1);
				border-radius: 0.2ex;
				padding: 0 0.4ex;
			}
			
			table .codeblock {
				/*I don't know why I have to set this manually, but
				if I don't, the codeblocks expand forever. They
				completely ignore the table's max-width.*/
				max-width: calc(975px/2.2);
			}
			
			h1,h2,h3 {
				line-height: 1.2;
				width: 100%;
			}
			
			p {
				width: 100%;
			}
			
			table {
				border-collapse: collapse; /*Fix transparent space between cells, where sticky elements weren't hiding content completely.*/
			}
			
			thead {
				position: sticky;
				top: 0px;
				background: white;
				text-align: left;
			}
			
			th, td {
				padding: 1ex;
				vertical-align: top;
			}
			
			body > table td:not(:last-child) {
				position: sticky;
				top: 3.4ex;
				background: white;
			}
			
			svg path {
				stroke: black;
			}
			
			svg text {
				font-family:sans-serif;
				font-size: 16px;
				line-height: 1.25;
				text-align: center;
				text-anchor: middle;
				pointer-events: none; /* Keep links, on rects, working when mouse is over text. */
				user-select: none;
			}
			
			svg rect {
				fill-opacity:.25;
				fill:#10bfbf;
				stroke:#107f7f
			}
			
			svg a:hover {
				opacity: 0.7;
			}
		</style>
		
		<script>
			//Remove HTML-formatting whitespace from code snippets. (Leading newlines, indentation.)
			document.addEventListener('DOMContentLoaded', ()=>{
				document.querySelectorAll('code').forEach(elem => {
					let lines = elem.innerHTML
						.split('\n')
						.filter(line=>line) //Filter to remove non-code lines, mainly the leading newline between <code> and the actual code.
					
					minLeadingTabs = lines
						.filter(line => line.trim())
						.reduce((minimum, line) => Math.min(line.split(/[^\t]/)[0].length, minimum), Infinity)
					
					elem.innerHTML = lines
						.map(line => line.replace(new RegExp(`^\t{0,${minLeadingTabs}}`), '')) //Remove leading snippet-level indentation, it provides nothing.
						.join('\n')
				})
			})
		</script>
	</head>
	<body>
		<h1>Chronos D-Bus API</h1>
		
		
		<p>This documentation covers the Chronos 1.4 Coordinator <a href="https://www.freedesktop.org/wiki/Software/dbus/">D-Bus</a> API. The internal camera D-Bus API has two major components: The D-Bus-based <a href="#control-api">Coordinator API</a> (formerly the Control API) and the D-Bus-based <a href="#video-api">Video API</a>.</p>
		
		<p>You can use the internal D-Bus APIs to write your own application on the camera. This application will be able to display a UI on the back of the camera as well as respond to remote HTTP requests over MiniUSB and the network.</p>
		
		<p>If you only need to control the camera remotely, you should consider using the <a href="https://github.com/krontech/chronos-web-interface">HTTP interface</a> instead. The HTTP interface lets you send commands to the camera over the network, and is used by the (planned) remote-control app. It is easier to develop using the HTTP interface than it is using the D-Bus interfaces.</p>
		
		<p>Note: All examples in this document are given in Python, since the <a href="index.html">reference client</a> was written in it.</p>
		
		<h2>Architecture</h2>
		
		<p>The D-Bus Coordinator and Video APIs sit between the hardware and the applications running on the camera.</p>
		
		<svg id="SVGRoot" version="1.1" viewBox="0 0 701 241" xmlns="http://www.w3.org/2000/svg">
			<g id="layer1" transform="translate(-29.5,-119.5)" inkscape:groupmode="layer" inkscape:label="Layer 1">
				<a href="#hardware"><rect id="rect2667" x="40" y="160" width="160" height="140"/></a>
				<a href="#control-api"><rect id="rect2669" x="300" y="160" width="160" height="60"/></a>
				<a href="https://github.com/krontech/chronos-cli/blob/master/src/pipeline/README.md"><rect id="rect2671" x="300" y="240" width="160" height="60"/></a>
				<a href="#user-interface"><rect id="rect2673" x="580" y="130" width="140" height="60"/></a>
				<a href="#http-interface"><rect id="rect2675" x="580" y="210" width="140" height="60"/></a>
				<a href="#ych"><rect id="rect2677" x="580" y="290" width="140" height="60" style="fill-opacity:1;fill:#6ecff0;stroke:#2c4d8e"/></a>
				<text id="text3352" x="120.00391" y="225.96484">
					<tspan id="tspan3350" x="120.00391" y="225.96484">Chronos 1.4</tspan><tspan id="tspan3354" x="120.00391" y="245.96484">Hardware</tspan>
				</text>
				<text id="text3358" x="380.33594" y="195.96484">
					<tspan id="tspan3356" x="380.33594" y="195.96484">Coordinator API</tspan>
				</text>
				<text id="text3362" x="380.72266" y="275.96484">
					<tspan id="tspan3360" x="380.72266" y="275.96484">Video API</tspan>
				</text>
				<text id="text3366" x="650.00391" y="154.41406">
					<tspan id="tspan3364" x="650.00391" y="154.41406">User Interface</tspan><tspan id="tspan3368" x="650.00391" y="174.41406">(chronos-gui-2)</tspan>
				</text>
				<text id="text3367" x="649.64062" y="234.41406">
					<tspan id="tspan3364-3" x="649.64062" y="234.41406">HTTP Interface</tspan>
					<tspan id="tspan3368-9" x="649.64062" y="254.41406">(planned)</tspan>
				</text>
				<text id="text3348" x="650.44141" y="325.96484" style="fill:#2c4d8e">
					<tspan id="tspan3346" x="650.44141" y="325.96484">Your Client Here</tspan>
				</text>
				<path id="path3393" d="m300 257.69-100-15.385" inkscape:connection-end="#rect2667" inkscape:connection-start="#rect2671" inkscape:connector-type="polyline"/>
				<path id="path3397" d="m460 180.31 120 37.698" inkscape:connection-end="#rect2675" inkscape:connection-start="#rect2669" inkscape:connector-type="polyline"/>
				<path id="path3401" d="m452.32 240 127.68-52.963" inkscape:connection-end="#rect2673" inkscape:connection-start="#rect2671" inkscape:connector-type="polyline"/>
				<path id="path3403" d="m460 260.52 120-14.222" inkscape:connection-end="#rect2675" inkscape:connection-start="#rect2671" inkscape:connector-type="polyline"/>
				<path id="path3405" d="m460 284.22 120 21.333" inkscape:connection-end="#rect2677" inkscape:connection-start="#rect2671" inkscape:connector-type="polyline"/>
				<path id="path3409" d="m580 167.78-120 13.333" inkscape:connection-end="#rect2669" inkscape:connection-start="#rect2673" inkscape:connector-type="polyline"/>
				<path id="path3411" d="m587.69 290-145.38-70" inkscape:connection-end="#rect2669" inkscape:connection-start="#rect2677" inkscape:connector-type="polyline"/>
				<path id="path3417" d="m200 217.69 100-15.385" inkscape:connection-end="#rect2669" inkscape:connection-start="#rect2667" inkscape:connector-type="polyline"/>
			</g>
		</svg>
		
		<p>The APIs provide a way to configure the camera hardware. The APIs also emit updates so that clients can keep themselves up-to-date when the camera is reconfigured. For example, if the HTTP interface receives a request to change the exposure time of the camera, then the user interface on the camera will need to update itself to reflect the new exposure time.</p>
		
		
		<h2><a name="hardware">Hardware</a></h2>
		
		<p>The APIs primarily drive the FPGA of the Chronos, as well as set up the video pipeline to display and save content. While the FPGA image itself is proprietary, the register definitions are available as part of the implementation of the APIs.</p>
		
		
		<h2><a name="control-api">Coordinator API</a></h2>
		
		<p>The Coordinator D-Bus API deals with configuring the camera, as opposed to the video API which is responsible for playing back and saving footage.</p>
		
		<h3>Connecting</h3>
		
		<p>To connect to the Coordinator API, connect to the D-Bus service/path/interface as in the following example:</p>
		
		<code>
			from PyQt5.QtDBus import QDBusInterface, QDBusConnection
			
			cameraControlAPI = QDBusInterface(
				"ca.krontech.chronos.control", #Service
				"/ca/krontech/chronos/control", #Path
				"", #Interface
				QDBusConnection.systemBus() )
		</code>
		
		<p>To use the mock interface, to avoid misconfiguring the camera during development, connect to the <code>ca.krontech.chronos.control<strong>.mock</strong></code> service instead of <code>ca.krontech.chronos.control</code>.</p>
		
		<h3>Methods</h3>
		
		<p>All methods result in a reply containing key/value pairs. The map can contain an optional 'value' entry with the data resulting from the function call, <strong>or</strong> in the case of an error an 'errorName' and 'message' entry. If there is no errorName, then no error should have occured.</p>
		
		<p>Available methods are:</p>
		<ul>
			<li><code><strong>get</strong>([string valueName, …]) → {string:value, …}</code> — Return camera setting values for all strings in the list passed in. See <a href="#values">Values</a> for a list of valid keys.</li>
			
			<li><code><strong>set</strong>({string valueName: any value, …})</code> — Update camera values named by string to their new value. See <a href="#values">Values</a> for a list of valid keys.</li>
			
			<li><code><strong>availableKeys</strong>() → [string valueName, …]</code> — Get a list of available camera settings keys, for use with <code>get</code> or <code>set</code>.</li>
			
			<li><code><strong>availableCalls</strong>() → [string callName, …]</code> — Get a list of available camera settings keys, for use with <code>get</code> or <code>set</code>.</li>
			
			<li><code><strong>powerDown</strong>()</code> — Turn off the camera. Useful in conjunction with the "Turn camera on when power connected" checkbox in the Battery & Power screen.</li>
			
			<li><code><strong>framerateForResolution</strong>(hRes: int, vRes: int) → float</code> — Returns the frames per seconds a resolution will record at. Non-valid resolutions will return undefined results.</li>
			
			<li><code><strong>resolutionIsValid</strong>(hOffset: int, vOffset: int, hRes: int, vRes: int) → bool</code> — Returns true if the supplied video resolution and offset is valid for recording. A resolution is not valid if it is offset too far. All parameters are positive integers.</li>
			
			<li>
				<code><strong>calibrate</strong>({string testName: boolean run})</code> — Calibrate the camera. Each calibration for which run is true is ran. Warning - some calibrations may require equipment to run correctly. For example, while black cal is easy to re-run, it is much harder to run white balance since you will need a diffuse, true-white light source. Available calibrations are:
				<ul>
					<li><code>analogCal</code>: Sensor internal calibration.</li>
					<li><code>blackCal</code>: The normal black calibration routine where you have to cover the lense.</li>
					<li><code>zeroTimeBlackCal</code>: The fast black calibration where exposure time is set to as close to zero as possible.</li>
					<li><code>whiteBalance</code>: Take a white reference and compute the white balance matrix. (API value <code>whiteBalance</code>.)</li>
				</ul>
			</li>
			
			<li><code><strong>takeStillReferenceForMotionTriggering</strong>()</code> — When motion triggering is used, the camera may need to be trained to recognise a still scene. For example, if there is some background motion such as trees swaying in the wind, this function will teach the camera to ignore it as background noise.</li>
			
			<li><code><strong>saveCalibrationData</strong>(str toFolder)</code> — Write all sensor calibration data (eg; black cal, white balance) to the folder specified. Usually, one would use the folder <code>'/dev/sda'</code>, as that represents the first external storage device plugged in on Linux systems such as the camera runs. Calibration data may be restored using the isomorphic <code>loadCalibrationData</code>.</li>
			
			<li><code><strong>loadCalibrationData</strong>(str fromFolder)</code> — Restores the calibration data saved by <code>saveCalibrationData</code>, overwriting all active calibration data.</li>
			
			<li><code><strong>applySoftwareUpdate</strong>()</code> — Install another firmware version from an external storage device. See the manual on "updating" for more details.</li>
			
			<li><code><strong>waterfallMotionMap</strong>({[id: str name], ['startFrame': int], ['endFrame': int]}) → {startFrame: int, endframe: int, heatmap: 16×n little-endian byte map}</code> — (unstable)
				<p>Generate a waterfall-style heatmap from each of the 16 quadrants of recorded motion data. Returns an 16×n greyscale bitmap, one byte per pixel.</p>
				<p>Arguments are a map specifying:
					<ul>
						<li>id: What segment ID to query. If not supplied, all recorded data will be considered "the segment".</li>
						<li>[startFrame = 0]: Optional frame to start from. Defaults to the first frame of the segment.</li>
						<li>[endFrame = ∞]: Optional frame to end at. Defaults to the last frame of the segment.</li>
					</ul>
				</p>
				<p>Segment IDs, and their respective startFrame and endFrames, can be read from the recordedSegments value.</p>
			</li>
			
			<li><code><strong>saveRegions</strong>([{[id: str], [start: int], [end: int], path: str, format: { fps: float, bpp: float, maxBitrate: float }}, …])</code> — (unstable) Save each region in the input list to file.
				<p>Save video clips to disk or network.</p>
				<p>Accepts a list of regions, returns a list of statuses.</p>
				<p>As with waterfallMotionMap, if no segment id is specified, 'all recorded data' is considered to be the segment, and start/end is relative to all recorded data.</p>
				Python example:
				<code class=codeblock>
					api.control('saveRegions', [{
						"start": 19104, 
						"end": 39801, 
						"id": 'ldPxTT5R', #from api value recordedSegments
						"path": '/dev/sda/',
						"format": {
							'fps': 29.97, #NTSC video
							'bpp': .7,
							'maxBitrate': 40, #mbps
						},
					}])
				</code>
				<p>A list of regions available to save and paths available to save to can be retrieved with <code>api.control('get', ['recordedSegments', 'externalStorage'])</code>.</p>
			</li>
			
			<li><code><strong>formatStorage</strong>(str path)</code> — Erase and prepare the device at <em>path</em> for saving video to. A list of paths available to format to can be retrieved with <code>api.control('get', ['externalStorage'])</code>. Be careful not to erase saved footage!</li>
			
			<li><code><strong>unmount</strong>(str path)</code> — Unmount the storage device mounted at <em>path</em>. A list of paths available to unmount to can be retrieved with <code>api.control('get', ['externalStorage'])</code>.
				<p>To remount a device, either reinsert it or SSH into the camera and run the mount command.</p>
			</li>
			
			<li><code><strong>df</strong>() → str output</code> — Returns text written to stdout by the linux utility <code>df</code>. This is mostly useful for debugging.
				<p>Example:
					<code class=codeblock>
						Filesystem     1K-blocks   Used Available Use% Mounted on
						/dev/root         757856 158420   5683476  22% /
						/dev/mmcblk0p1     39497   3961     35537  11% /boot
						/dev/sda1          39497   2973     36525   8% /media/sda1
						/dev/sda2         757856 167288   5574608  23% /media/sda2
					</code>
				</p>
			</li>
			
			<li><code><strong>testNetworkStorageCredentials</strong>({[networkStorageAddress: str], [networkStorageUsername: str], [networkStoragePassword: str]}) → str error</code> — Check if a remote file share is available. Returns either a string containing the error message if the share is not connectable-to, or an empty string if the credentials were valid. networkStorageAddress, networkStorageUsername, and networkStoragePassword may be provided to override the API values of the same names.</li>
		</ul>
		
		<p>In addition, when a camera setting is changed, a signal named the key is emitted on the D-Bus interface. It can be intercepted with <code>QDBusConnection.systemBus().connect('ca.krontech.chronos.control.mock', '/', '', NAME_OF_KEY, CALLBACK)</code>.
		
		
		<h3><a name="values">Values</a></h3>
		
		<p>API Values hold and reflect the state of the camera. They are read and written using the <code>get</code> and <code>set</code> method calls listed above. A list of value names can be retrieved by calling the <code>availableKeys</code> method.</p>
		
		<p>Values can have different levels of mutability:</p>
		<ul>
			<li><strong>Variable</strong> values can be set through the API, but may be changed externally as well. They can be set, retrieved, and observed. (Observation, in this case, means a D-Bus signal with the same name as the value will be emitted. Refer to <a href="../src/api.py#observe">api.py:observe</a> for an example.)</li>
			<li><strong>Property</strong> values, on the other hand, only change in response to external stimulus. Properties can't be set, but they can be retrieved and observed as they changed. These are things like battery level and trigger status.</li>
			<li><strong>Constant</strong> values do not change over the course of a connection, although they may be changed if the camera firmware is upgraded. For example, firmware version and the amount of RAM installed are both constants.</li>
		</ul>
		
		<p>All strings are <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a> encoded. All integers are little-endian. All float values are 64-bit <a href="http://ieeexplore.ieee.org/servlet/opac?punumber=2355">IEEE-754</a> encoded.</p>
		
		<p>Available values are:</p>
		<table>
			<thead>
				<tr>
					<th>Value Name</th>
					<th>Type</th>
					<th>Mutability</th>
					<th>Description</th>
				</tr>
			</thead>
			
			<tbody>
				<tr>
					<td><code>HTTPPort</code></td>
					<td>integer</td>
					<td>variable</td>
					<td>Specify the port for the web server to run on. This is used for the web app and HTTP API. You can enable the web app and HTTP API by setting <code>localHTTPAccess</code> or <code>remoteHTTPAccess</code> to <code>True</code>.</td>
				</tr>
				<tr>
					<td><code>SSHPort</code></td>
					<td>integer</td>
					<td>variable</td>
					<td>Set the Secure Shell port. By default, port 22 is used, but it is recommended to use a high random port for day-to-day use. It defaults to port 22 because it's easier to connect to, but it is less secure because this is where everyone looks for SSH.</td>
				</tr>
				<tr>
					<td><code>availableRecording<br>AnalogGains</code></td>
					<td>list</td>
					<td>constant</td>
					<td>Get a list of integer gains the image sensor output can be amplified by. Each element of the list is a map with two keys, <code>multiplier</code> and <code>dB</code>. The <code>multiplier</code> values can be used to set <code>previewAnalogGainMultiplier</code> and <code>recordingAnalogGainMultiplier</code>. The decibel values are purely informational. Higher amplification levels will produce a noisier image. Amplification is an analog operation, versus a digital operation like you might get post-processing a video to be brighter.</td>
				</tr>
				<tr>
					<td><code>batteryCharge</code></td>
					<td>float</td>
					<td>property</td>
					<td>On a scale of 0.0 to 1.0, how full is the camera battery? 0 is dead, and 1 is fully charged.</td>
				</tr>
				<tr>
					<td><code>batteryVoltage</code></td>
					<td>float</td>
					<td>property</td>
					<td>A measure of the power the removable battery is putting out, in volts. A happy battery outputs between 12v and 12.5v. This value is graphed on the battery screen on the Chronos.</td>
				</tr>
				<tr>
					<td><code>cameraApiVersion</code></td>
					<td>string</td>
					<td>constant</td>
					<td>The current iteration of this API. Adheres to <a href="https://semver.org/">SemVer</a>. Example: <code>1.13.0</code></td>
				</tr>
				<tr>
					<td><code>cameraDescription</code></td>
					<td>string</td>
					<td>variable</td>
					<td>Does nothing. Can be used to give an easy-to-identify name to a camera when many cameras are being used. Supports emoji.</td>
				</tr>
				<tr>
					<td><code>cameraFpgaVersion</code></td>
					<td>string</td>
					<td>constant</td>
					<td>The firmware iteration the <a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">field-programmable gate array</a> inside the Chronos is running. (The FPGA is primarily responsible for recording the high-speed video coming off the sensor to a buffer in RAM.) Example: <code>1.13.0</code></td>
				</tr>
				<tr>
					<td><code>cameraMemoryGB</code></td>
					<td>float</td>
					<td>constant</td>
					<td>Amount of RAM installed in the Chronos in <a href="https://en.wikipedia.org/wiki/Gigabyte">GB</a> (vs <a href="https://en.wikipedia.org/wiki/Gibibyte">GiB</a>). This will correspond to the memory amount printed on the bottom of your camera, if you haven't made any modification.</td>
				</tr>
				<tr>
					<td><code>cameraModel</code></td>
					<td>string</td>
					<td>constant</td>
					<td>The product identifier of the camera hosting the API. This corresponds to the model printed on the bottom of your camera. Example: <code>CR14-1.0</code></td>
				</tr>
				<tr>
					<td><code>cameraSerial</code></td>
					<td>string</td>
					<td>constant</td>
					<td>The serial number of the product the API is running on. This corresponds to the SN printed on the bottom of your camera. Example: <code>00204</code></td>
				</tr>
				<tr>
					<td><code>colorMatrix</code></td>
					<td>list</td>
					<td>variable</td>
					<td>A 3x3 matrix controlling <a href="https://en.wikipedia.org/wiki/Color_balance">colour balance</a> of the recorded video. To disable colour correction, set to the identity matrix:
					<code class=codeblock>
						[[1,0,0],
						 [0,1,0],
						 [0,0,1]]
					</code>
					</td>
				</tr>
				<tr>
					<td><code>commonlySupported<br>Resolutions</code></td>
					<td>list</td>
					<td>constant</td>
					<td>
						A list of maps. Each map indicates a preset by specifying <code>hRes</code> (int, px), <code>vRes</code> (int, px), and maximum <code>framerate</code> (float, frames per second). Partial example:
						<code class="codeblock">
							[{
								'hRes': 1280, 
								'vRes': 1024, 
								'framerate': 1057.362,
							}, …]
						</code>
					</td>
				</tr>
				<tr>
					<td><code>datetime</code></td>
					<td>string</td>
					<td>variable</td>
					<td>iso 8601-formatted date, <code>YYYY-MM-DDTHH:MM:SS.mmmmmm</code>. Detailed in <a href="https://docs.python.org/3/library/datetime.html#datetime.datetime.isoformat">the Python datetime docs</a>.</td>
				</tr>
				<tr>
					<td><code>currentCameraState</code></td>
					<td>enum</td>
					<td>property</td>
					<td>Indicates what the camera is doing. One of <code>normal</code>, <code>saving</code> or <code>recording</code>. When saving (to file), parts of the API may be unresponsive. The main difference between <code>normal</code> and <code>recording</code> is whether the red indicator lights on the chronos are red or not. Some actions, like 'stop recording' or 'stop saving', only make sense in certain states.</td>
				</tr>
				<tr>
					<td><code>currentVideoState</code></td>
					<td>enum</td>
					<td>variable</td>
					<td>Indicates what the video display is showing. One of <code>viewfinder</code> or <code>playback</code>.</colgroup>. In <code>viewfinder</code> mode, the video on the back of the camera is showing what the sensor is seeing. In <code>playback</code> mode, the video is showing footage previously recorded in RAM.</td>
				</tr>
				<tr>
					<td><code>dimScreenWhenNotInUse</code></td>
					<td>boolean</td>
					<td>variable</td>
					<td>After a period, dim the screen backlight to conserve battery power. This has a fairly small effect overall.</td>
				</tr>
				<tr>
					<td><code>disableOverwriting<br>RingBuffer</code></td>
					<td>boolean</td>
					<td>variable</td>
					<td>In segmented mode, disable overwriting earlier recorded ring buffer segments.</td>
				</tr>
				<tr>
					<td><code>externalStorage</code></td>
					<td>list</td>
					<td>property</td>
					<td>External storage device partitions.
			
						<p>Returns a list of maps, one map per partition on each external storage device. (Storage devices are things like SD cards, USB thumb sticks, etc.)</p>
						
						Maps contain the following keys:
						<ul>
							<li>name: The given name of the partition.</li>
							<li>device: The name of the device the partition is on. If a device has more than one partition, each partition will have the same device name.</li>
							<li>path: Where on the camera's filesystem the device is mounted to. Unlike name, guaranteed to be unique.</li>
							<li>size: The amount of space on the partition, in bytes.</li>
							<li>free: The amount of available space on the partition, in bytes. Note that size and free may not fit in a 32-bit integer.</li>
							<li>interface: Either a <code>usb</code> drive, an <code>sd</code> card port, or a <code>network</code> mount.</li>
						</ul>
						
						<code>externalStorage</code> example:
						<code class=codeblock>
							[{
								"name": "Testdisk",
								"device": "mmcblk0p1",
								"path": "/dev/sda",
								"size": 1294839100, #bytes
								"free": 4591,
								"interface": "sd",
							},{
								"name": "Toastdesk",
								"device": "sdc1",
								"path": "/dev/sdc1",
								"size": 2930232316000,
								"free": 1418341032982,
								"interface": "usb", 
							}]
						</code>
					</td>
				</tr>
				<tr>
					<td><code>externallyPowered</code></td>
					<td>boolean</td>
					<td>property</td>
					<td>Returns True if the camera is running on mains power. In this mode, the battery will recharge until full.</td>
				</tr>
				<tr>
					<td><a name=focusPeakingColor><code>focusPeakingColor</code></a></td>
					<td>integer</td>
					<td>variable</td>
					<td>
						An integer specifying the color of focus peaking, one of the available focus aids. Like HTML/CSS, this value is composed of four packed 8-bit channels, representing Red, Green, Blue, and Alpha (strength). In <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal</a>, this is formatted as 0x<span style="color: #D00F;">RR</span><span style="color: #0B0F;">GG</span><span style="color: #00DF;">BB</span><span style="color: #000F;">AA</span>. For example, <code style="color: #AA00AAFF;">0xAA00AAFF</code> is maximum-strength purple, because red and blue are both set to AA, and alpha is set to FF. <code style="color: #C1681988;">0xC1681988</code> is half-strength brown.
						<br>
						To turn focus peaking on or off, set <code>focusPeakingIntensity</code>.
					</td>
				</tr>
				<tr>
					<td><code>focusPeakingIntensity</code></td>
					<td>string</td>
					<td>variable</td>
					<td>One of <code>'off'</code>, <code>'low'</code>, <code>'medium'</code>, <code>'high'</code>. Higher intensity means more color on screen.</td>
				</tr>
				<tr>
					<td><code>localHTTPAccess</code></td>
					<td>boolean</td>
					<td>variable</td>
					<td>Enable web access (HTTP API and web app) over the local network, ie, 192.168.x.x. Note that <code>networkPassword</code> <em>must</em> be set before any network-based control is actually turned on.</td>
				</tr>
				<tr>
					<td><code>localSSHAccess</code></td>
					<td>boolean</td>
					<td>variable</td>
					<td>Enable command-line access over the local network, ie, 192.168.x.x. Note that <code>networkPassword</code> <em>must</em> be set before any network-based control is actually turned on. It is strongly recommended to set up key-based authentication as soon as possible, and disable ssh password login via the command line.</td>
				</tr>
				<tr>
					<td><code>motionTriggerAdaption</code></td>
					<td>string</td>
					<td>variable</td>
					<td>Set how quickly the motion triggering algorithm adapts to non-triggering motion sources. Can be set to <code>high</code>, <code>medium</code>, <code>low</code>, or <code>off</code> to disable learning entirely. Even if adaption is disabled, you can call the <code>takeStillReferenceFor<br>MotionTriggering()</code> method to retrain the motion trigger.</td>
				</tr>
				<tr>
					<td><code>motionTriggerHOffset</code></td>
					<td>integer</td>
					<td>variable</td>
					<td rowspan=4>The region within the recorded picture which the motion trigger monitors for activity. HRes is the horizontal size of the box, VRes is vertical size of the box, HOffset is the horizontal offset from the upper-left corner of the recorded image, and VOffset is the vertical offset. (The recorded image can be changed with analogous recordingHRes/VRes/HOffset/VOffset, assuming <code>videoState</code> is <code>'recording'</code> or <code>'pre-recording'</code>. Otherwise, no motion triggering occurs.)<br>See <code>motionTriggerAdaption</code> and <code>takeStillReferenceForMotionTriggering()</code> for configuring motion within the motion trigger region.</td>
				</tr>
				<tr>
					<td><code>motionTriggerHRes</code></td>
					<td>integer</td>
					<td>variable</td>
					<!--Overridden, see motionTriggerHOffset.-->
				</tr>
				<tr>
					<td><code>motionTriggerVOffset</code></td>
					<td>integer</td>
					<td>variable</td>
					<!--Overridden, see motionTriggerHOffset.-->
				</tr>
				<tr>
					<td><code>motionTriggerVRes</code></td>
					<td>integer</td>
					<td>variable</td>
					<!--Overridden, see motionTriggerHOffset.-->
				</tr>
				<tr>
					<td><code>recordingMode</code></td>
					<td>string</td>
					<td>variable</td>
					<td>Configure how the camera records. <code>'normal'</code> causes one trigger to record the whole buffer. <code>'segmented'</code> causes one trigger to record one a segment, the size of which is determined by dividing the total available record length by <code>recordedSegments</code>. <code>gated burst</code> uses the full buffer, but only records when an input signal is high. Signals can be configured by setting <code>triggerConfiguration</code> value.</td>
				</tr>
				<tr>
					<td><code>recordingSegments</code></td>
					<td>float</td>
					<td>variable</td>
					<td>Set how many individual video clips are produced while in segmented record mode. (See <code>recordingMode</code> for details.) For example, if you wanted to record 4 events, you might call <code>api.set({'recordingSegments': 4, 'recordingMode', 'segmented'}))</code>. The minimum is 1, the maximum the of number of frames in the recording buffer. Note that the default on-board UI may not handle viewing extremely large numbers of segments well, since each segment is displayed and saved separately.</td>
				</tr>
				<tr>
					<td><code>recordedSegments</code></td>
					<td>list</td>
					<td>property</td>
					<td>A list of the recorded segments of video. Will always contain one entry unless <code>recordingMode</code> is <code>'segmented'</code>. Each entry is a map containing the following keys:
						<ul>
							<li>int <code>'start'</code>: First frame of the recorded segment, inclusive.</li>
							<li>int <code>'end'</code>: Final frame of the recorded segment, exclusive.</li>
							<li>int <code>'hres'</code>: Horizontal resolution of the video, in pixels.</li>
							<li>int <code>'vres'</code>: Vertical resolution of the video, also in pixels.</li>
							<li>int <code>'milliframerate'</code>: Framerate the segment was recorded at, in millionths of a frame per second. See <code>sensorMilliframerate</code> for details.</li>
							<li>string <code>'id'</code>: A unique 8-character identifier for the segment. (Uniqueness is not guranteed long-term. Generate a UUID in that case.)</li>
						</ul>
					</td>
				</tr>
				<tr>
					<td><code>networkInterfaces</code></td>
					<td>list</td>
					<td>property</td>
					<td>A list of connections to the outside world through. Add an element to this list by plugging in an Ethernet cable, the On-The-Go Mini USB cable, or a supported Wi-Fi dongle. (No dongles are officially supported yet, however.) Each element contains the following keys:
						<ul>
							<li>str <code>'id'</code>: The name of the network device, for example, <code>'enp0s25'</code> or <code>'wlp4s0'</code>.</li>
							<li>str <code>'name'</code>: The name of the physical item providing connectivity. Example: <code>'Ethernet'</code> or <code>'Mini USB'</code>.</li>
							<li>str <code>'localAddress4'</code>: The IPv4 address of the camera on the local network. (You can often set up port forwarding to expose this to the internet.) For example, the camera was randomly assigned <code>'192.168.1.14'</code> when I connected it to the office network. Then, using the OTG cable, the camera assigned itself <code>'192.168.12.1'</code> as it always does.</li>
							<li>str <code>'localAddress6'</code>: The IPv6 address of the camera on the local network. For example, on the office local-area network, I can access the camera at <code>'fe80::22c3:8fff:fe3b:966a'</code>.</li>
							<li>str <code>'remoteAddress4'</code>: As with <code>'localAddress4'</code>, but the routable internet address instead of just the local address. You usually have to configure your local network to forward requests to your camera to get this.</li>
							<li>str <code>'remoteAddress6'</code>: As above, but with IPv6 instead of IPv4.</li>
						</ul>
						<p>Note: If no address is available, then the field will be an empty string (<code>''</code>). At least one address will be populated, or the entry will not appear. Remote addresses <em>always</em> have a local version.</p>
						For example, using the <a href="https://github.com/krontech/chronos-gui-2/blob/master/src/api.py">Python API client</a>, <code>api.get('networkInterfaces')</code> yields
						<code class=codeblock>
							[{
								'id': 'enp0s25',
								'name': 'Ethernet',
								'localAddress4': '192.168.1.135',
								'localAddress6':
									'fe80::22c3:8fff:fe3b:966a',
								'remoteAddress4': '205.250.126.92',
								'remoteAddress6': '',
							},{
								'id': 'wlp4s0',
								'name': 'Mini USB',
								'localAddress4': '192.168.12.1',
								'localAddress6':
									'fe80::f81b:26ff:fee7:24dd',
								'remoteAddress4': '',
								'remoteAddress6': '',
							}]
						</code>
					</td>
				</tr>
				<tr>
					<td><code>networkPassword</code></td>
					<td>string</td>
					<td>variable</td>
					<td>The password which must be supplied for HTTP or SSH access. <em>If no password is set, network access is disabled.</em> Retrieving this field will yield an arbitrary number of <code>•</code>s.</td>
				</tr>
				<tr>
					<td><code>networkStorageAddress</code></td>
					<td>string</td>
					<td>variable</td>
					<td rowspan=3>Network storage allows the camera to save video to a remote device via a network connection. Address: IP address of the network storage device (ie, a Samba share) to connect to when saving. Password and Username provide authentication. The currently set credentials can be tested by calling <code>testNetworkStorageCredentials({})</code>. If you want to test your credentials before setting them, you can pass them to the function.</td>
				</tr>
				<tr>
					<td><code>networkStoragePassword</code></td>
					<td>string</td>
					<td>variable</td>
					<!-- Overridden. -->
				</tr>
				<tr>
					<td><code>networkStorageUsername</code></td>
					<td>string</td>
					<td>variable</td>
					<!-- Overridden. -->
				</tr>
				<tr>
					<td><code>playbackFrame</code></td>
					<td>int</td>
					<td>variable</td>
					<td>The current frame video playback is on. Since this may update very frequently, change events will not fire for this value.</td>
				</tr>
				<tr>
					<td><code>playbackFramerate</code></td>
					<td>int</td>
					<td>variable</td>
					<td>A delta applied to playbackFrame, once every 16ms at most. Above 60fps, frames will be dropped, and below 60fps, the playbackFrame will be updated less frequently.</td>
				</tr>
				<tr>
					<td><code>powerOnWhen<br>MainsConnected</code></td>
					<td>boolean</td>
					<td>variable</td>
					<td>Set to <code>True</code> to have the camera turn on when it is plugged in. The inverse of this, turning off when the charger is disconnected, is achieved by setting the camera to turn off at any battery percentage. For example, to make the camera turn off when it is unpowered and turn on when it is powered again - effectively only using the battery to finish saving - you could make the following call:
					<code class=codeblock>
						api.control('set', {
							'powerOnWhenMainsConnected': True,
							'saveAndPowerDownWhenLowBattery': True,
							'saveAndPowerDownLowBatteryLevel': 100,
						})
					</code>
					</td>
				</tr>
				<tr>
					<td><code>previewAnalog<br>GainMultiplier</code></td>
					<td>integer</td>
					<td>variable</td>
					<td>One of the <code>availableRecordingAnalogGains</code>. Higher values amplify the light level, but as this is an analog operation this also increases image noise. Only used if in preview mode. See also <code>recordingAnalogGainMultiplier</code>.</td>
				</tr>
				<tr>
					<td><code>previewHOffset</code></td>
					<td>integer</td>
					<td>variable</td>
					<td rowspan=4>Like <code>recordingHOffset</code>/<code>recordingHRes</code>/<code>recordingVOffset</code>/<code>recordingVRes</code> but used for preview mode. If <code>currentCameraState</code> is not set to <code>preview</code>, these properties has no effect.</td>
				</tr>
				<tr>
					<td><code>previewHRes</code></td>
					<td>integer</td>
					<td>variable</td>
					<!-- Overridden. -->
				</tr>
				<tr>
					<td><code>previewVOffset</code></td>
					<td>integer</td>
					<td>variable</td>
					<!-- Overridden. -->
				</tr>
				<tr>
					<td><code>previewVRes</code></td>
					<td>integer</td>
					<td>variable</td>
					<!-- Overridden. -->
				</tr>
				<tr>
					<td><code>recordedSegments</code></td>
					<td>list</td>
					<td>property</td>
					<td>A list of maps, one for each separate segment of video recorded. Each map having the following keys:
						<ul>
							<li>str <code>'id'</code>: A short unique random identifier for this segment. Useful for disambiguating segments.</li>
							<li>int <code>'start'</code>: Start frame (relative to beginning of buffer) of this segment.</li>
							<li>int <code>'end'</code>: End frame (relative to beginning of buffer) of this segment. Segment length, in frames, may be calculated by subtracting start from end.</li>
							<li>int <code>'hres'</code>: The horizontal resolution of the recorded video.</li>
							<li>int <code>'vres'</code>: The vertical resolution of the recorded video.</li>
							<li>[int <code>'milliframerate'</code>]: The framerate the segment was recorded at. <code>None</code> if <code>recordingMode</code> is <code>'gated burst'</code>, since the camera can't calculate a single framerate from the gating signal in that case. <!--However, timing data will be embedded in the video if saved in TIFF or DNG formats.--></li>
						</ul>
						The maximum number of segments is <code>recordingSegments</code>. There can only be more than one segment if <code>recordingMode</code> was set to <code>'segmented'</code> while recording.
					</td>
				</td>
				<tr>
					<td><code>recordingAnalog<br>GainMultiplier</code></td>
					<td>integer</td>
					<td>variable</td>
					<td>One of the <code>availableRecordingAnalogGains</code>. Higher values amplify the light level, but as this is an analog operation this also increases image noise. Overridden by <code>previewAnalogGainMultiplier</code> when in <code>videoState</code> is <code>'preview'</code>.</td>
				</td>
				<tr>
					<td><code>recordingExposureNs</code></td>
					<td>integer</td>
					<td>variable</td>
					<td>Controls image brightness. Longer exposures lead to a brighter image, but shorter exposures cause less motion blur. The exposure must be 5000ns shorter than the recording period. If set to a value greater than that, it will bump up the recording period appropriately.</td>
				</td>
				<tr>
					<td><code>recordingPeriod</code></td>
					<td>integer</td>
					<td>variable</td>
					<td>Value, in nanoseconds, indicating the total amount of time to take to record a frame.</td>
				</td>
				<tr>
					<td><code>recordingHRes</code></td>
					<td></td>
					<td></td>
					<td rowspan=4></td>
				</td>
				<tr>
					<td><code>recordingHoffset</code></td>
					<td></td>
					<td></td>
					<!-- Overridden. -->
				</td>
				<tr>
					<td><code>recordingVRes</code></td>
					<td></td>
					<td></td>
					<!-- Overridden. -->
				</td>
				<tr>
					<td><code>recordingVoffset</code></td>
					<td></td>
					<td></td>
					<!-- Overridden. -->
				</td>
				<tr>
					<td><code>recordingVStep</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>remoteHTTPAccess</code></td>
					<td>boolean</td>
					<td>variable</td>
					<td>Enable web access (HTTP API and web app) with no restrictions. The HTTP API and web app will be accessible from any device able to route to it. Note that <code>networkPassword</code> <em>must</em> be set before any network-based control is actually turned on. It is strongly suggested to set <code>networkPassword</code> to a multi-word passphrase in this case, to make it hard to guess.</td>
				</tr>
				<tr>
					<td><code>remoteSSHAccess</code></td>
					<td>boolean</td>
					<td>variable</td>
					<td>Enable command-line access to the camera with no ip-based restrictions. Note that <code>networkPassword</code> <em>must</em> be set before any network-based control is actually turned on. It is strongly recommended to set up key-based authentication over the local network or the OTG cable (which is always enabled), and disable ssh password login via the command line.</td>
				</tr>
				<tr>
					<td><code>saveAndPowerDown<br>LowBatteryLevel</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>saveAndPowerDown<br>WhenLowBattery</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>sensorFramerateMax</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorHIncrement</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorHMax</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorHMin</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorMaxExposureNs</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorMaxShutterAngle</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorMilliframerate</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>sensorMinExposureNs</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorName</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorPixelFormat</code></td>
					<td>string</td>
					<td>constant</td>
					<td>Either <code>BYR2</code> for color cameras or <code>y12</code> for monochromatic cameras. This corresponds to the Color or Mono information printed on the bottom of the Chronos.</td>
				</td>
				<tr>
					<td><code>sensorPixelRate</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorQuantizeTimingNs</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorRecordsColor</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>sensorVIncrement</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorVMax</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>sensorVMin</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>showBlackClipping<br>ZebraStripes</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>showWhiteClipping<br>ZebraStripes</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>timingExposureDelayNs</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>timingExposureDelayNs</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>timingMaxExposureNs</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>timingMaxPeriod</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>timingMaxShutterAngle</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>timingMinExposureNs</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>timingMinPeriod</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>timingQuantization</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>totalAvailableFrames</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>totalRecordedFrames</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>triggerCapabilities</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>triggerConfiguration</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>triggerDelay</code></td>
					<td></td>
					<td></td>
					<td>in frames</td>
				</tr>
				<tr>
					<td><code>triggerDelayNs</code></td>
					<td></td>
					<td></td>
					<td>in nanoseconds</td>
				</td>
				<tr>
					<td><code>triggerState</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>triggers</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>whiteBalance</code></td>
					<td></td>
					<td></td>
					<td></td>
				</td>
				<tr>
					<td><code>videoDisplayDevice</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>videoDisplayHeight</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>videoDisplayWidth</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>videoDisplayX</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>videoDisplayY</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>videoState</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td><code>whiteBalance</code></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
			</tbody>
		</table>
		
		<p>Some settings related to the video pipeline take a little while to update, so it's recommended to set them all at once with one call to to <code>set</code>.</p>
		
		
		<h3>Reference Client</h3>
		
		<p>A Python reference client for the control API is available. If you're using Python to script, it may be useful as a library. Otherwise, it may serve as a useful example how to connect to and use the D-Bus API.</p>
		
		<p>It is <strong>not</strong> required to use the reference client. The client simply sands down some of the rough edges of the D-Bus API. For example, when <code>get</code>ting or <code>set</code>ting a single value, the reference client automatically converts the single value into the list the D-Bus API requires. It also emits an update signal immediately on subscription, which eliminates the need for separate initialiser code in many cases.</p>
		
		<p>The reference API has the following available methods:</p>
		
		<ul>
			<li><code><strong>video</strong>(methodName: string, optional args: any)</code> — Convenience method to invoke one of the D-Bus API Video methods. See the <a href="https://github.com/krontech/chronos-cli/blob/master/src/pipeline/README.md">video api documentation</a> for details.</li>
			<li><code><strong>control</strong>(methodName: string, optional args: any)</code> — </li>
			<li><code><strong>get</strong>(string or [strings])</code> — Convenience method to invoke one of the D-Bus API Video methods. See the <a href="#values">control settings keys</a> for a list of values. If a string is passed, this method will automatically wrap it in a list before calling the underlying D-Bus method and unwrap the returned list.</li>
			<li><code><strong>set</strong>({key: value})</code> — Wrapper for <code>control('set', {…})</code>. See the <a href="#values">control settings keys</a> for a list of values.</li>
			<li><code><strong>observe</strong>(valueName: string, callback: Callable[[Any], None])</code> — Invoke the callback with the new value when the value changes. The value is initially presumed to be unknown, and so is considered to change to the current value is when the subscription is started. valueName is one of the <a href="#values">control settings keys</a>.</li>
			<li><code><strong>observe_future_only</strong></code> — Like <code>observe</code>, but the callback is not called on subscription. This is useful for some of the more complex compound values which can arise around sliders and such.</li>
			<li><code><strong>@silenceCallbacks(Qt Widget)</strong></code> — Function decorator for a callback. Before a decorated callback is called, this turns off events for the supplied Qt Widget. For example, on the main screen of the UI, the callback
				<code class="codeblock">
					@pyqtSlot(int)
					@silenceCallbacks('uiExposureSlider')
					def updateExposureNs(self, newExposureNs):
						self.uiExposureSlider.setValue(newExposureNs)
				</code>
			is used by 
				<code class="codeblock">
					api.observe('recordingExposureNs', self.updateExposureNs)
				</code>
			to update the exposure slider when the exposure is changed externally.
			</li>
		</ul>
		
		
		
		<h2><a name="video-api">Video API</a></h2>
		<p>The video interface deals with getting the video data from A to B.</p>
		
		<p>The <a href="https://github.com/krontech/chronos-cli/blob/master/src/pipeline/README.md">full documentation</a> for the video API is available in the <a href="https://github.com/krontech/chronos-cli">chronos-cli repository</a>.</p>
		
		
		
		<h2><a name="user-interface">User Interface</a></h2>
		<p>The user interface, on the screen on the back of the Chronos, uses the D-Bus API to drive the camera and keep itself in sync with the state the camera is in.</p>
		
		<h2><a name="http-interface">HTTP Interface</a></h2>
		<p><em>I have not written this program yet, but what is documented as follows will follow.</em></p>
		<p>The HTTP interface exposes a web API. It also provides web app which uses the web API. The web app can be used from any phone, tablet, or laptop running a modern web browser.</p>
		
		<p>The HTTP interface is very similar to the D-Bus interface. It mostly exposes the same method calls, and provides the same events. However, it also contains an authentication mechanism so other people can't control your camera without your permission. The D-Bus API does not need an authentication mechanism, since anything capable of talking to it is already running on the camera and can do anything the API can do.</p>
		
		
		
		<h2><a name="ych">Your Client Here</a></h2>
		
		<p>So, you have a specialized application you want the camera to perform? Perhaps you just want to lock down the back-of-camera UI? Luckily for you, it is easy to develop your own application to run on the Chronos.</p>
		
		<p>There are two approaches to developing an app. You can write the code on the camera, or you can write the code on a virtual machine and copy it to the camera later. If you want to set up a VM, refer to <a href="../util/chronos debian setup instructions.txt">~util/chronos debian setup instructions.txt</a>. The following instructions assume you have a working development environment, either on the camera or in a virtual machine.</p>
		
		
		<h3>Connecting to the Camera</h3>
		
		<p>Developing directly on your Chronos, via SSH or file upload, is simpler than developing on a virtual machine. If you develop via SSH, you'll usually run commands and edit files in-place on the camera with Vim or Emacs. If you prefer file upload, you'll set up a little watcher-script that will restart your application when you change a file. The advantage of uploading the files is being able to edit them locally, with your preferred text editor, although this method is a little more complex. Either way the files on the camera are changed, the result is the same.</p>
		
		<p>Before making any changes to your camera, it is strongly recommended to make a backup of your system SD card. Pop the SD card out of the bottom of the camera, insert it into your computer, and then make a backup of the card filesystems. (Not the files themselves.) On Linux, this can be done with <code>gzip /dev/sdb --to-stdout --verbose > chronos-fs-$(date +%F).gz</code>, where <code>/dev/sdb</code> is the device you just plugged in. You can list plugged-in devices with <code>lsblk</code>. (You should see <code>BOOT</code> and <code>ROOTFS</code> on your microSD card.) After you've taken your backup, which will take a while to complete, test it by restoring it to a <em>different</em> microSD card. If you don't have a spare card to test with, it is advised to say a brief prayer instead.</p>
		
		<p>You can connect via the local network by plugging an Ethernet cable into your camera, or connect directly to your computer with a MicroUSB cable. Either way, the camera will get an IP address which you can SSH to. For example, I have my camera connected to my PC via USB, so I run <code>ssh root@192.168.12.1</code> to connect to my camera. I can also visit <code>fish://root@192.168.12.1/root/</code> in Dolphin to browse the files on my camera graphically. When prompted, the password is "chronos", or whatever you set it to.</p>
		
		<p>The camera runs Debian 7 (Wheezy). As such, most common linuxisims will still work, but modern programs must be compiled from scratch. The back-of-camera UI, chronos-gui-2, lives in <code>~/gui</code>. For your own app, you may wish to build new screens for chronos-gui-2, or use it as a reference for developing your own Qt app. The D-Bus API resides in <code>~/chronos-cli</code>. All software running on the CPU is open source, and can be <a href="https://github.com/krontech">freely downloaded from GitHub</a>. If you'd like to contribute a bug fix or a new feature to the existing app, please drop us a line on the forum so we can coordinate!</p>
		
		<p>So, basically, make a new <code>my_client_app.py</code> file on the camera and run it with <code>python3 my_client_app.py</code>. Refer to above for how to make it do stuff.</p>
	</body>
</html>